{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "# OR Suppress only specific warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWz3b9Z3BecR",
        "outputId": "2f2fd236-bd82-4067-89d9-d9d088b0b356"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTdggHF1BPM_",
        "outputId": "67b8376b-cf2f-46c7-96b1-36a4a348387a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Performance:\n",
            "Accuracy: 0.8888888888888888\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      0.50      0.67         4\n",
            "           3       0.86      1.00      0.92        12\n",
            "\n",
            "    accuracy                           0.89        18\n",
            "   macro avg       0.95      0.83      0.86        18\n",
            "weighted avg       0.90      0.89      0.87        18\n",
            "\n",
            "\n",
            "Scaled 'Group' Model Performance:\n",
            "Accuracy: 0.2222222222222222\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.25      1.00      0.40         4\n",
            "           3       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.22        18\n",
            "   macro avg       0.08      0.33      0.13        18\n",
            "weighted avg       0.06      0.22      0.09        18\n",
            "\n",
            "\n",
            "Original model took 29 iterations to converge.\n",
            "Scaled 'Group' model took 224 iterations to converge.\n",
            "Therefore, scaling Group I reduces the convergence rate.\n"
          ]
        }
      ],
      "source": [
        "# Load your dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Periodic Table of Elements Goodman Sciences Github.csv', usecols=['AtomicMass', 'NumberofNeutrons', 'NumberofProtons', 'NumberofElectrons', 'Period', 'Group', 'Phase'])\n",
        "\n",
        "# If 'Phase' is textual, encode it to numeric\n",
        "if data['Phase'].dtype == 'object':\n",
        "    le = LabelEncoder()\n",
        "    data['Phase'] = le.fit_transform(data['Phase'])\n",
        "\n",
        "# Drop rows with NaN values in the specified columns\n",
        "data = data.dropna(subset=['AtomicMass', 'NumberofNeutrons', 'NumberofProtons', 'NumberofElectrons', 'Period', 'Group', 'Phase'])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data[['AtomicMass', 'NumberofNeutrons', 'NumberofProtons', 'NumberofElectrons', 'Period', 'Group']]\n",
        "y = data['Phase']\n",
        "\n",
        "# Split the dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Feature Scaling: Standardize features by removing the mean and scaling to unit variance\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Training the original Softmax Regression model\n",
        "classifier_original = LogisticRegression(multi_class='multinomial', solver='sag', random_state=0, verbose=0, max_iter=10000)\n",
        "classifier_original.fit(X_train, y_train)\n",
        "\n",
        "# Creating a copy of the training data and scaling the 'Group' column by a factor of 10\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[:, list(X.columns).index('Group')] *= 10\n",
        "\n",
        "# Training the new Softmax Regression model with the scaled 'Group'\n",
        "classifier_scaled = LogisticRegression(multi_class='multinomial', solver='sag', random_state=0, verbose=0, max_iter=10000)\n",
        "classifier_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predicting the Test set results for the original model\n",
        "y_pred_original = classifier_original.predict(X_test)\n",
        "\n",
        "# Evaluate the original model\n",
        "print(\"Original Model Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_original))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_original))\n",
        "\n",
        "# Predicting the Test set results for the scaled model\n",
        "y_pred_scaled = classifier_scaled.predict(sc.transform(X_test))  # Scaling X_test before predictions\n",
        "\n",
        "# Evaluate the scaled model\n",
        "print(\"\\nScaled 'Group' Model Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_scaled))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_scaled))\n",
        "\n",
        "# Comparing convergence\n",
        "print(f\"\\nOriginal model took {classifier_original.n_iter_[0]} iterations to converge.\")\n",
        "print(f\"Scaled 'Group' model took {classifier_scaled.n_iter_[0]} iterations to converge.\")\n",
        "print(\"Therefore, scaling Group I reduces the convergence rate.\")\n",
        "\n"
      ]
    }
  ]
}